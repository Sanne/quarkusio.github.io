---
layout: post
title: 'Exploring Project Leyden'
date: 2024-07-17
tags: leyden
synopsis: 'Project Leyden: exploring its potential for Quarkus users.'
author: leydenquarkus
---
:imagesdir: /assets/images/posts/leyden

You might have heard of https://openjdk.org/projects/leyden/[Project Leyden]: an initiative within the OpenJDK project with very ambitious goals.

When casually namedropping "I'm looking into Project Leyden" with some fellow Java developers these days, I would usually spot some off guard thinking: "Leyden..?", to then offer a hasty save "Ah, right, the project to improve startup times".

Which is not wrong, as indeed startup times improvements are one of its goals, yet we believe the other stated goals of the project offer even greated potential for our favourite platform, and its users.

[quote]
____
The primary goal of this Project is to improve the startup time, time to peak performance, and footprint of Java programs.

-- Project Leyden, first thing on its project page
____

To keep costs down, in all forms such as energy efficiency, required hardware resources, and indeed money, it's indeed useful to keep bootstrap times reasonably low, but it's even more effective to reduce the time to peak performance, such as the time it takes for the JVM to "warm up", and reducing the footprint of our applications, such as total memory, has very direct impact.

From a Quarkus perspective, we've done a fairly good job on all such metrics but we're constantly on the lookout to improve, so Project Leyden got our attention and we're working with our collagues from the OpenJDK team at Red Hat, who are directly involved in implementing Leyden with the wider OpenJDK group: this blog post today is a collaboration among teams.

To better understand the scope of the potential improvements, we need to take a step back and discuss how the JVM works today, especially how our application is started and iteratively evolves from interpreting our bytecode to its highest performance mode: running native code which is highly optimized, adapted to the particular hardware, the configuration of the day, and the specific workloads it's been asked to perform. No other runtime is able to match the JVM on this.

By default, as it boots, Java is a lazy interpreted language. The content of our JAR file is not executable machine code, but Java bytecode. The JVM will only compile the bytecode of a class the first time it gets referenced during execution. When a target class cannot be found the program throws a ClassNotFoundException.

== How does the JVM work?
 
When a method first executes a new bytecode, a field get or put, or an invoke of some other method; the JVM doesn't just attempt to load the relevant class. It checks for a matching field or method of the correct type and attaches linkage information to the bytecode so that subsequent execution can proceed efficiently without the need to repeat the lookup. 

image::Java_Compilation_Intro.svg[Compilation work diagram,float="right",align="center"]

=== Linkage

Linkage is done via two independent steps:

The first step is internally modelling each class, its methods and its field based on the bytecode. This step happens when a class is loaded for the first time.

The second requires resolving references from some loaded class (or its method bytecode) to other classes (and their methods and fields) or to constant (String or Class) objects on the heap. Note that in the bytecode these references are by symbolic name i.e. UTF8 strings. But in the internal model used to execute the code, the links have to be established explicitly, using memory pointers to actual memory positions.

So, that means link resolution involves traversing the class base, potentially requiring loading of a referenced class or creation of a referenced String or Class object on the heap memory. This second step mostly happens when bytecode is executed. 

In a few cases it happens as a side effect of the load. For example, super classes are loaded and linked immediately. The results are cached in an internal model of the constant pool, replacing a symbol entry with a pointer and updating the tag for the entry. 

At the same time, details of where a field is located or how to enter a method (interpreter or compiled entry address) are cached in the constant pool cache. These latter details are needed in order to access fields or call methods from the interpreter. They are also used as inputs to the compiler when it tries to compile a method.

=== Runtime Optimisation

Another lazy operation the JVM performs is JIT (runtime) compilation. Method bytecode is normally interpreted but the JVM will lazily translate bytecode to equivalent machine code. It performs this compilation task selectively, only bothering to compile methods that have been invoked quite a few times. It will also lazily upgrade compiled code after it has been executed very many times. 

An initial 'tier' 1 compile runs quickly, generating code that is only lightly optimised using profile information gathered during interpretation. A tier 2 recompile will instrument the code to track more details about control flow. Tier 3 compilation adds further instrumentation that records many more details about what gets executed, including with what type of values. Finally a tier 4 compilation uses the gathered profile information to perform a great deal of optimization. This final stage of compilation can take a very long time so compilation above tier 1 only happens for a small subset of very frequently executed methods.

image::Java_Compilation_B.svg[Code gets optimised incrementally, diagram,float="right",align="center"]

Peak optimization is reached when most of the code running is compiled at the highest Tier.

This laziness approach results in the exact same bytecode being loaded and parsed for many classes every run, the exact same linkage being established every run, the exact same compilation, profiling and recompilation being attempted at every run. This can noticeably slow down JDK startup, application startup and application warmup (time to peak running).

We could speed up startup and, more crucially, warmup time if we do some of these lazy actions before. Compiling code for peak performance also requires quite some resources, so performing this work ahead of time can also save precious CPU cycles during the application bootstrap, and can manifest in substantial memory savings as well.

But there are some limitations on what we can optimise before runtime just by looking at the source code. For example, extensive use of reflection prevents the compiler from predicting which symbols will be loaded, linked, and most used at runtime.

The statistics and profiling that HotSpot uses on runtime to improve the machine code don’t have to get lost after you shut down your application. They can be saved to be reused on subsequent runs. You can also make training runs of your application before deploying them on production, to get those statistics and profilings. As long as the conditions of the training run are similar as in production (same type of hardware, same load and type of requests,...), the results will greatly improve startup and response time of your application.

This can be done using the https://docs.oracle.com/en/java/javase/21/vm/class-data-sharing.html[Class Data Sharing feature]. Using training runs, the JVM has access to profiling and statistics about which classes it has used before. This helps the startup time because the JVM already knows what is going to be needed and can load it before it gets used.

== What is Leyden?

https://openjdk.org/projects/leyden/[Project Leyden] is an initiative from the OpenJDK team to improve startup time, time to peak performance, and footprint of Java applications. This is an ongoing experiment that is currently being developed by the joint effort of teams from different companies.

Leyden is a general umbrella project to address slow startup and large footprint. Leyden premain addresses the startup problem by caching loaded class info, class linkage and compilation profile during a training run so it can reuse them to actively populate, link and compile code in a production run. Leyden is extending CDS to add the extra stuff to the mix.

Note that the project is evolving rapidly: some of the things explained in this article may change since the time of being written. If you plan on getting involved at a more technical level, follow the development in Jira and the Leyden mailing list.

=== Why it’s interesting to Quarkus

Although Quarkus is already doing a lot of work on the Ahead of Time phase to speed up warmup and response time, the enhancements that Leyden is bringing to the table are more related to how the JVM behaves. Complementing both approaches, the advantages we can expect from the combination of Quarkus and Leyden are beyond anything you can find with either of them separated.

Since the potential for such technological collaboration is strong, the Quarkus and OpenJDK teams are working together on various prototypes and anyone in the Quarkus community would be very welcome to join as well.

== Current status

There are already experimental https://jdk.java.net/leyden/[early-access builds of Leyden] that can be tested based on https://openjdk.org/jeps/8315737[this draft JEP about Ahead-of-Time Class Linking]. With the https://www.youtube.com/watch?v=lnth19Kf-x0[Leyden Project], the training run idea has been extended to a wider range of data structures, creating the Cache Data Store(CDS). Now the training data contains:
Class file events with historical data (Classes loaded and linked, Compilations)
Resolution of API points and indy (stored in constant pool images in the CDS archive). If you have lambdas in your code, they are captured here.
Execution profiles and some compiled native code (all tiers)

image::Java_Compilation_Leyden.svg[Leyden execution, diagram,float="right",align="center"]

This new CDS implementation not only tracks which classes to load, but it also saves the interrelationships that link classes together. During runtime, the JVM will know the estimated final size of a class, allowing it to calculate in AoT time locations of fields and methods. This is useful because we can prepare other classes that call those fields and methods with the appropriate pointer instead of having to wait until runtime and make the HotSpot calculate the memory pointer on the fly.

=== Some known limitations

This is an experimental project being developed by multiple teams with different approaches and focuses. Limitations explained here are being worked on at the time of writing this blog post.

One of the main issues is that functionality is currently only available for x86_64 and AArch64 architectures at the moment. 

Also, current developments rely on a flat classpath. If the application is using custom classloaders, then it may not benefit as much as it could as it may miss caching many classes. Same happens if the application is intensively using reflection. Quarkus avoids reflection whenever possible, preferring to resolve reflective calls at build time as well - so there’s a nice synergy right there. However Quarkus in “fast-jar” mode, which is the default packaging mode, will use a custom classloader which currently would get in the way of some Leyden optimisations. One could use a different packaging mode in Quarkus to get more prominent benefits from Leyden, but doing so would disable other Quarkus optimisations, so the comparison wouldn’t be entirely fair today.

The focus on these first early releases has been on bootstrap times. There are measurable, significant startup time improvements, due to AoT loading and linking. In some cases, these improvements on startup time have worsened the memory footprint of some applications. That’s an already known issue that is being worked on, and the expected outcome is to improve memory footprint as well, so we would suggest not worrying too much about total memory consumption at this stage.

Since the CDS archives include machine specific optimisations such as the native code generated by the C2 compiler, the training run and the production run must be done on the same type of hardware and JDK versions; it also requires using the same JAR-based classpaths and the same command line options. 

Although you can use a different Main class for running the application, maybe a test class that simulates real usage.

=== What is on the roadmap for Leyden?

There’s still work to be done regarding classes that can’t be loaded and linked in AoT with the current implementation. For example, classes loaded using a user-defined class loader. There’s also room to improve the way the training runs are made, maybe allowing the user to tweak the results to influence decisions.

Currently, the https://bugs.openjdk.org/browse/JDK-8326035[Z Garbage Collector] does not support CDS object archiving. There is an active effort to make sure all Garbage Collectors are compatible with these enhancements.

There are also other things planned in the roadmap for Leyden, like adding condensers. https://openjdk.org/projects/leyden/notes/03-toward-condensers[Condensers] will be composable transformers of the source code in AoT that modify the source code optimising it. Each developer will be able to define a pipeline of condensers that improves their source code before compiling it into Bytecode; this is very interesting to the Quarkus team but condensers aren’t available yet

The OpenJDK team is working on adding a more complete code cache to the CDS to avoid that first compilation for trained data, by just loading the compiled code directly from the cache; our colleagues from Red Hat’s OpenJDK team are directly involved in implementing this. This could include, among others, auxiliary code used to interface compiled code to runtime, interpreter or other compiled runtimes.

== How to play with it 

The first step would be to install one of the early Leden builds that you can find in https://jdk.java.net/leyden/

Make sure that you have installed it correctly by running the following command:

[source, console]
----
$ jdk-24/bin/java --version
openjdk 24-leydenpremain 2025-03-18
OpenJDK Runtime Environment (build 24-leydenpremain+2-8)
OpenJDK 64-Bit Server VM (build 24-leydenpremain+2-8, mixed mode, sharing)
----

Go to the application you want to test Leyden with and make a first training run:

[source, console]
----
$ java -XX:CacheDataStore=archive.cds -jar $YOUR_JAR_FILE
----

This will generate the archive files with all the profiling information needed to speed up the production run.

Now that we have them, we can run our application using the Leyden enhancements:

[source, console]
----
$ java -XX:CacheDataStore=archive.cds -XX:+AOTClassLinking -jar $YOUR_JAR_FILE
----

== Potentially needed workarounds

Since it’s early days for the Leyden project, there are some known limitations. The following instructions shouldn’t be necessary for the final versions but you might need them today.

=== Force the use of G1GC

To benefit from the natively compiled code in CDS archives, the garbage collector used at runtime needs to match the same garbage collector used when you recorded the CDS archives. 

Remember that the JVM’s default choice of garbage collector is based on ergonomics; normally this is nice but it can cause some confusion in this case; for example if you build on a large server it will pick G1GC by default, but then when you run the application on a server with constrained memory it would, by default, pick SerialGC.

To avoid this it’s best to pick a garbage collector explicitly; and since several CDS related optimisations today only apply to G1, let’s enforce the use of G1GC.

Force using G1GC:

[source, console]
----
-XX:+UseG1GC
----

N.B. you need to use this consistently on both the process generating the CDS archives and the runtime.

=== Force the G1 Region sizes

As identified and reported by the Quarkus team to our colleagues working on Project Leyden, beyond enforcing a specific garbage collector one should also ensure that the code stored in CDS archives is being generated with the same heap region sizes as what’s going to be used at runtime, or one risks segmentation faults caused by it wrongly identifying regions.
See https://bugs.openjdk.org/browse/JDK-8335440 for details, or simply set:

Configure G1HeapRegionSize explicitly:

[source, console]
----
-XX:G1HeapRegionSize=1048576
----

N.B. you need to use this consistently on both the process generating the CDS archives and the runtime.

=== Failure to terminate in containers

This issue has already been resolved, but in case you’re using an older version of project Leyden and it fails to exit on regular container termination, you might be affected by https://bugs.openjdk.org/browse/JDK-8333794[JDK-8333794].

Workaround for JDK-8333794:

[source, console]
----
-Djdk.console=java.basebroken
----

== Will Leyden replace GraalVM's native-image capabilities?

The short answer is no.

If you want the absolute smallest footprint and ensure that absolutely no "dynamic" adaptations happen at runtime, GraalVM native images are the way to go. Just think about it: to support the dynamic aspects that the JVM normally provides,
even in very minimal form, you would need some code which is able to perform this work, and some memory and some computational resources to run such code and adapt your runtime safely; this is a complex feature and will never be completely free, even in the case Leyden evolved significantly beyond the current plans.

The architecture of Quarkus enables developers to define an application in strict "closed world" style, and this approach works extremely well in combination with GraalVM native images, but this design works indeed very well on the bigger, dynamic JVMs as well.

The ability that Quarkus offers to created a closed world application doesn't imply that you should necessarily be doing so; in fact there are many applications which could benefit from a bit more dynamism, a bit more runtime configurability or auto-adaptability, and Quarkus also allows to create such applications while still benefitting from very substantial efficiency improvements over competing architectures, and even competing runtimes and languages.

We're very excited by Project Leyden as it allows to substantially improve bootstrap times, warmup times, and overall costs even for the "regular" JVM, so retaining all the benefits of a dynamic runtime and an adaptative JIT compiler, and this will be a fantastic option for all those applications for which a fully AOT native image might not be suitable: you'll get some of the benefits from native-image (not all of them) but essentially for free, at no drawbacks.

We also hope it will bring better defined semantics in regards to running certain phases “ahead of time” (or later); there is a very interesting read on this topic by Mark Reinhold: “Selectively Shifting and Constraining Computation” ; from a perspective of Quarkus extensions maintainers, we can confirm that this would be very welcome, and also improve the quality and maintainability of applications compiled with GraalVM native-image(s).

For these reasons, Quarkus will definitely not deprecate support for native images; it's more plausible that, eventually, the "full JVM" will always be benefitting from Leyden powered improvements, and as usual we'll work to make these benefits work in synergy with our architecture, and at minimal effort for you all.

It's a great time to be a Java developer!


== How can I make sure this will work for me?

The best way to make sure your application benefits from Leyden is to start experimenting early, be involved in the development, and it would be great to add real-world feedback from a perspective of Quarkus users.
If you spend some time testing your application with the https://jdk.java.net/leyden/[early-access builds of Leyden], and reporting any https://bugs.openjdk.org/browse/JDK-8335735?jql=issuetype%20%3D%20Bug%20AND%20status%20%3D%20Open%20AND%20labels%20%3D%20leyden[bugs] or weird behaviour; you will ensure the developers will take your specificities into account.

The OpenJDK issue tracker isn’t open to everyone, but you’re also very welcome to provide feedback on our https://quarkus.io/discussion/[Quarkus channels]; we can then relay any improvement ideas to our colleagues who are directly working on project Leyden.

